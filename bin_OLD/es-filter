#!/usr/bin/env python3

# Removes documents from pipeline that match blacklisted word combinations.
# The filter file contains a json dict with keyword and a corresponding list of words that if found,
# should lead to dropping this document.
# Example:
# {"nets": ["brooklyn"]}
# will drop all docs where "nets" is found in the same field together with "brooklyn".

__author__ = 'eelseth'


from eslib.procs import DocumentFilter
import argparse
from eslib.prog import progname


def main():
    """

    """
    help_f = "A single or comma separated list of fields to filter on."
    help_F = "The path to a JSON filter file with the format {'keyword': ['remove','doc','if','exists']}"
    parser = argparse.ArgumentParser()
    parser.add_argument('-f', '--field'        , required=True, help=help_f)
    parser.add_argument('-F', '--filterFile'   , required=True, help=help_F)
    parser.add_argument(      "--name"         , help="Process name.", default=None)
    parser.add_argument(      "--debug"        , action="store_true")
    parser.add_argument("filenames", nargs="*" , help="If not specified stdin will be used instead.")



    args = parser.parse_args()

    dp = DocumentFilter(args.name or progname())
    dp.filter_file = args.filterFile
    dp.filter_fields = args.field.split(',')

    if args.debug: dp.debuglevel = 0

    dp.run(args.filenames)


if __name__ == "__main__": main()
